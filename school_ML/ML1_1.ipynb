{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqFyzPDuFDvI",
        "colab_type": "text"
      },
      "source": [
        "#**Первое занятие по PyTorch**\n",
        "\n",
        "Изучаем основные понятия и три ключевых пакета PyTorch, разбираемся, как формируется стандартный, универсальный алгоритм построения и анализа модели.\n",
        "\n",
        "Этот алгоритм вы сможете сразу использовать для проверки самых разных гипотез.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI4Zv-dtka20",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*Дискламер: местами будут использоваться явные англицизмы -- чтобы быть в курсе, довольно часто они используются в тематических обсуждениях на русскоязычных форумах, и более компактны и наглядны.*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Параллельно очень рекомендую к прочтению эту серию статей (перевод книги Майкла Нильсена \"Neural Networks and Deep Learning\")**\n",
        "https://habr.com/ru/post/463171/\n",
        "\n",
        "В ней подробно рассматривается вся базовая теория нейронных сетей и глубокого обучения.\n",
        "\n",
        "---\n",
        "\n",
        "##**Простая линейная регрессия**\n",
        "\n",
        "Есть простая линейная функция,  \n",
        "\n",
        "`y = 1 + 2 * x + шум`\n",
        "\n",
        "которая в контексте машинного обучения трактуется как прогнозирование некоторых результатов. \n",
        "\n",
        "x -- это **входные данные, признаки (features)**;\n",
        "y -- это **прогноз**.\n",
        "\n",
        "Например, если автомобиль едет с линейной скоростью, то пройденное им расстояние зависит от времени езды. В данных из реальной жизни в такой зависимости всегда будет шум -- скорость всё время немножечко плавает, возможны остановки на светофорах и т. д.\n",
        "\n",
        "Принципиальный момент. Чем вообще мы занимаемся?\n",
        "\n",
        "В нашей функции есть два коэффициента 1 и 2, или в общем случае\n",
        "\n",
        "`y = a + b * x`\n",
        "\n",
        "это коэффициенты (**параметры**) a и b, которые ещё называются **метки (labels)**.\n",
        "\n",
        "Про наши данные (например, набор пар значений \"время - расстояние\") мы знаем только, что они с большой вероятностью моделируются подобной линейной регрессией. То есть то, что нам надо найти -- это такие a и b, что соответствующая функция будет выдавать значения, как можно более близкие к обучающим.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25-CG5zmmtya",
        "colab_type": "text"
      },
      "source": [
        "##**Немного теории: градиентный спуск**\n",
        "\n",
        "**Градиент (gradient)** -- это частная производная (производная по одной  конкретной переменной).\n",
        "\n",
        "*Кто не помнит школьный курс математики, производная -- это просто скорость изменения чего-то. Например, если вы едете с фиксированной скоростью, она не меняется, то и производная её (ускорение) будет равно нулю. А если скорость всё время растёт, то и градиент (ускорение) будет больше нуля, и тем он будет больше, чем сильнее увеличивается скорость.*\n",
        "\n",
        "В общем случае модель включает в себя множество параметров (скорость автомобиля -- это функция от множества критериев), и градиент показывает, как сильно меняется (со временем например) какой-то один конкретный параметр (считаем частную производную по этому параметру), подразумевая, что остальные если и меняются, то незначительно.\n",
        "\n",
        "**Лосс (loss)** -- ошибка, погрешность (например, среднеквадратическая ошибка).\n",
        "\n",
        "Оптимизационный механизм, отыскивающий нужные нам коэффициенты, называется \"**градиентный спуск**\" (подобных алгоритмов много). Его работа складывается из четырёх шагов.\n",
        "\n",
        "1) считаем лосс (стратегически стремимся к его минимизации).\n",
        "\n",
        "2) вычисляем градиенты. \n",
        "\n",
        "У нас в модели, как уже говорилось, есть два параметра a и b, для которых мы должны считать градиенты. Мы хотим определить, как будет меняться лосс при изменении каждого из этих параметров.\n",
        "\n",
        "3) обновляем параметры. Так как мы хотим минимизировать лосс, то градиенты берутся с обратным знаком, и учитывается также коэффициент скорости обучения.\n",
        "\n",
        "**Скорость обучения (learning rate)** -- некоторый коэффициент, который учитывается при изменении параметров в градиентном спуске.\n",
        "\n",
        "4) при необходимости проверяем что получилось, и переходим к п.1.\n",
        "\n",
        "Такой цикл из четырёх шагов называется **эпоха (epoch)**.\n",
        "Эпоха -- один цикл оптимизации (например, шаг градиентного спуска), когда была пересчитана каждая точка выборки.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZht9-DMpNmk",
        "colab_type": "text"
      },
      "source": [
        "##**Градиентный спуск на базе NumPy**\n",
        "\n",
        "Реализуем сперва градиентный спуск классическим способом: только с помощью стандартной библиотеки численных методов NumPy.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL87rRR0TJeE",
        "colab_type": "text"
      },
      "source": [
        "Подробное введение в линейную алгебру и NumPy для начинающих:\n",
        "\n",
        "https://github.com/DLSchool/dlschool/tree/master/02.%20Linear%20Algebra%2C%20Numpy\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsd8wI9uUVDY",
        "colab_type": "text"
      },
      "source": [
        "Введение в Matplotlib (рисуем графики):\n",
        "\n",
        "https://github.com/DLSchool/dlschool/tree/master/03.%20Pandas%2C%20Matplotlib%2C%20ML%20basics\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1_wBE0WU1Z8",
        "colab_type": "text"
      },
      "source": [
        "Введение в линейные модели и градиентный спуск:\n",
        "\n",
        "https://github.com/DLSchool/dlschool/tree/master/04.%20Linear%20Models\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsY44JTKBhQA",
        "colab_type": "code",
        "outputId": "89924dbe-7c02-49f9-c585-1b6e047c79f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# \n",
        "# оригинал\n",
        "# https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# инициализация повторяемой последовательности случайных чисел\n",
        "np.random.seed(42) \n",
        "\n",
        "# создаём np-массив из 100 случайных чисел в диапазоне 0..1\n",
        "sz = 100\n",
        "x = np.random.rand(sz, 1) \n",
        "\n",
        "# строим функцию y = f(x) и добавляем немного гауссова шума\n",
        "y = 1 + 2 * x + 0.1 * np.random.randn(sz, 1) \n",
        "\n",
        "# формируем индексы от 0 до 99 \n",
        "idx = np.arange(sz)\n",
        "# случайно их тасуем\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "\n",
        "# первые 80 случайных индексов (значений x) используем для обучения\n",
        "sz80 = (int)(sz*0.8)\n",
        "train_idx = idx[: sz80]\n",
        "\n",
        "# оставшиеся 20 -- для валидации\n",
        "val_idx = idx[sz80:]\n",
        "\n",
        "# формируем наборы обучающих данных\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "# и наборы для валидации\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "# выводим на экран\n",
        "plt.scatter(x_train, y_train) \n",
        "plt.title('Обучающая выборка') \n",
        "plt.show()\n",
        "plt.scatter(x_val, y_val, color= \"red\") \n",
        "plt.title('Проверочная выборка') \n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEnGkSyYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA1VF9YHUtmy",
        "colab_type": "code",
        "outputId": "47d8885e-eaa2-449f-da36-bb36e6a33601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# задаём начальные случайные значения коэффициентам линейной регрессии \n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "print(a,b)\n",
        "\n",
        "# скорость обучения\n",
        "lr = 0.1\n",
        "# количество эпох\n",
        "n_epochs = 1000\n",
        "\n",
        "# основной цикл\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "    # рассчитываем результирующий массив с текущими коэффициентами a и b\n",
        "    # на основе обучающей выборки \n",
        "    yhat = a + b * x_train\n",
        "    \n",
        "    # 1. определяем лосс\n",
        "    # сперва считаем отклонение нового результата от обучающего:\n",
        "    error = (y_train - yhat)\n",
        "    # и затем считаем среднеквадратическую ошибку:\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # 2. считаем градиенты (вспоминая формулу производной)\n",
        "    # для коэффициента a\n",
        "    a_grad = -2 * error.mean()\n",
        "    # для коэффициента b\n",
        "    b_grad = -2 * (x_train * error).mean()\n",
        "    \n",
        "    # 3. обновляем параметры, используя коэффициент скорости обучения, \n",
        "    # градиенты берём с обратным знаком\n",
        "    a = a - lr * a_grad\n",
        "    b = b - lr * b_grad\n",
        "print(a,b)    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49671415] [-0.1382643]\n",
            "[1.02354094] [1.96896411]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1qI2IV2pxyO",
        "colab_type": "text"
      },
      "source": [
        "Итак, исходные коэффициенты были очень далеки от оригинальных:\n",
        "[0.49671415] [-0.1382643]\n",
        "\n",
        "Но итоговые результаты оказались весьма близки к ним:\n",
        "[1.02354094] [1.96896411]\n",
        "\n",
        "Более того, на основании нашей случайной выборки какие-то более точные значения коэффициентов получить уже практически нельзя.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnxBhwkHp_z8",
        "colab_type": "text"
      },
      "source": [
        "##**Тензоры**\n",
        "\n",
        "В пакетах машинного обучения основная работа ведётся как правило с тензорами.\n",
        "\n",
        "**Тензор** -- это обычно вектор (одномерный массив), двумерный массив (матрица), в общем случае многомерный массив. \n",
        "\n",
        "Операции над тензорами очень эффективно выполняются графическими процессорами, поэтому библиотеки машинного обучения оптимизируются под GPU.\n",
        "\n",
        "Над тензорами возможны как обычные арифметические матричные операции, так и множество дополнительных действий. \n",
        "\n",
        "**Скаляр** -- это массив с нулём измерений, или просто одно число.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPMCGh3qVe-k",
        "colab_type": "text"
      },
      "source": [
        "Введение и практика с тензорами на PyTorch, рекомендую пройти:\n",
        "\n",
        "https://github.com/DLSchool/dlschool/blob/master/06.%20PyTorch/%5Bseminar%5Dpytorch_basics.ipynb\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hv1alqxqhmE",
        "colab_type": "text"
      },
      "source": [
        "##**Берёмся за PyTorch**\n",
        "\n",
        "В PyTorch активно применяется понятие девайса.\n",
        "\n",
        "**Девайс (device)** -- устройство, на котором обрабатываются тензоры (графический процессор или обычный).\n",
        "\n",
        "Начало работы с PyTorch обычно строится по типовому шаблону:\n",
        "\n",
        "-- проверяем, доступны ли ресурсы GPU;\n",
        "\n",
        "-- готовим наши данные, преобразовывая в формат тензоров (для массивов NumPy это функция from_numpy);\n",
        "\n",
        "-- при желании данные можно привести к типу меньшей точности (например, 32-разрядному float), чтобы сэкономить ресурсы;\n",
        "\n",
        "-- выгружаем данные на конкретный девайс (GPU или обычный процессор) с помощью функции to().\n",
        "\n",
        "Тип тензора можно получить методом type(), который вернёт, например, torch.FloatTensor, если используется обычный процессор, или torch.cuda.FloatTensor, если GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6aeaa5fZqpK",
        "colab_type": "code",
        "outputId": "9fbf09bc-c984-44c8-9843-ff1a76f00641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch # подключаем основной пакет PyTorch\n",
        "\n",
        "# стандартная команда настройки девайса на GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# Наши исходные данные хранятся в формате массивов NumPy, \n",
        "# требуется преобразовать их в формат тензоров PyTorch,\n",
        "# привести к типу float и выгрузить на девайс\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "print(x_train_tensor.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns0XT4uYrQ6g",
        "colab_type": "text"
      },
      "source": [
        "Теперь запрограммируем градиентный спуск, те же четыре шага, с помощью PyTorch.\n",
        "\n",
        "Сперва проинициализируем параметры (тензоры) a и b, используя случайные функции PyTorch.\n",
        "\n",
        "В параметрах функции генерации случайного значения torch.randn() в дополнение к понятным параметрам dtype (желаемый тип результирующего тензора) и целевой девайс (device), указывается очень важный requires_grad = True. Его смысл подробнее рассмотрим позже, но основная его идея в том, что он задаёт автоматическое вычисление градиента для данного тензора. Мы ведь считаем градиенты именно по этим двум параметрам a и b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwVawk-PHnVW",
        "colab_type": "code",
        "outputId": "b34ef444-8874-4178-f523-34899f2e696c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# инициализация повторяемой посл-ти случайных чисел\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# задаём начальные случайные значения коэффициентам линейной регрессии \n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6At-XHNsAUE",
        "colab_type": "text"
      },
      "source": [
        "Мы получим такой результат: \n",
        "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
        "(значения a и b могут быть другими, в зависимости от версии PyTorch).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fMgF9nksRl8",
        "colab_type": "text"
      },
      "source": [
        "##**Autograd: автоматизируем расчёт градиентов**\n",
        "\n",
        "Autograd -- пакет автоматического дифференцирования PyTorch (один из трёх ключевых). Он очень крутой: можно забыть про частные производные, ручное программирование формул производных и многую другую математику -- теперь она скрыта под капотом autograd!\n",
        "\n",
        "https://pytorch.org/docs/stable/autograd.html?highlight=autograd#module-torch.autograd\n",
        "\n",
        "Нам теперь не нужно вручную программировать производные -- **вычисления всех градиентов выполняет универсальный метод backward()**. Так как мы вычисляем частные производные для лосса, к нему этот метод и применяем, вся магия совершится автоматически внутри него. А текущие значения градиентов мы можем получить обращением к атрибуту **grad** соответствующего тензора.\n",
        "\n",
        "Однако если далее мы захотим обновить параметры по старой схеме, появятся ошибки.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRNMuJ4dgV-I",
        "colab_type": "code",
        "outputId": "86e78521-a0c0-4e3e-a024-a5808bfcd830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# скорость обучения\n",
        "lr = 0.1\n",
        "\n",
        "# количество эпох\n",
        "n_epochs = 1000 \n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "    # как и в примере с numpy, записываем нашу линейную зависимость,\n",
        "    # только теперь в качестве обучающей выборки -- тензор\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # 1. считаем лосс как и раньше\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # 2. вычисляем градиенты автоматически!\n",
        "    loss.backward()\n",
        "    \n",
        "    \n",
        "    # ПЕРВАЯ ПОПЫТКА (неверно)\n",
        "    # TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
        "    # a = a - lr * a.grad\n",
        "    # b = b - lr * b.grad\n",
        "\n",
        "    # ВТОРАЯ ПОПЫТКА (неверно)\n",
        "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "    # a -= lr * a.grad\n",
        "    # b -= lr * b.grad        \n",
        "    \n",
        "    # ТРЕТЬЯ ПОПЫТКА (верно)\n",
        "    with torch.no_grad():\n",
        "        a -= lr * a.grad\n",
        "        b -= lr * b.grad\n",
        "    \n",
        "    # Обнуляем градиенты вручную\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm5TTEjemt7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRz0O8-bBuYs",
        "colab_type": "text"
      },
      "source": [
        "В первом случае мы не учли, что по умолчанию **все действия и операции над тензорами иммутабельны**. Мы формируем новые тензоры в процессе арифметических операций и при переназначении нашим параметрам их же обновлённых значений градиенты сбрасываются в начальное значение None, и возникает подобная ошибка.\n",
        "\n",
        "Нам надо выполнять обновления параметров непосредственно в них самих (**in place**) -- работать с ними как с мутабельными объектами, без создания промежуточных данных. Но и вторая попытка обновления с помощью стандартной питоновской in-place операции -= тоже выдаст ошибку.\n",
        "\n",
        "\n",
        "Дело в том, что PyTorch строит **динамический вычислительный граф** (см. далее) для каждой питоновской операции, которая прямо или косвенно связана с тензорами, для которых считаются градиенты. И чтобы временно отключить такой режим по умолчанию, надо воспользоваться методом **torch.no_grad()**, который позволяет выполнять операции над тензорами в отрыве от графа вычислений. Именно это мы и делаем в третьей попытке.\n",
        "\n",
        "\n",
        "И наконец, надо ещё учесть, что **градиенты автоматически не обнуляются, а накапливаются** -- в каждой эпохе их надо обнулять вручную. В PyTorch принято, что все методы по умолчанию иммутабельны (не воздействуют на своего родителя), а их мутабельные (in place) версии (полезные например, когда мы не хотим создавать промежуточные копии крупных объектов) отличаются символом подчёркивания в конце своего названия.\n",
        "Обнуление градиента \"на месте\" выполнит соответствующий метод **zero_()**.\n",
        "\n",
        "Итак, мы получаем итоговый результат, очень близкий к версии NumPy:\n",
        "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y67gyH5Du1A",
        "colab_type": "text"
      },
      "source": [
        "##**Динамический граф вычислений**\n",
        "\n",
        "**Вычислительный граф** -- это направленный граф, в узлах которого выполняются некоторые вычисления. \n",
        "\n",
        "Вычисления в узлах графа используют данные, которые были вычислены в \"предыдущих\" узлах.\n",
        "\n",
        "Каждый узел графа -- по сути чистая функция, получающая на вход данные от связанных с ним узлов; по этой причине исполнение вычислительного графа хорошо распараллеливается.\n",
        "\n",
        "По большому счёту, от фреймворков машинного обучения требуются три основные вещи: **формировать граф вычислений, дифференцировать его, и вычислять**.\n",
        "В PyTorch такой граф строится динамически при запуске кода, и по нему можно проходить как вперёд, от начала к концу, так и обратно, от конца в начало.\n",
        "\n",
        "Зачем же этот граф нужен, как он связан с нашим кодом, как это вообще работает?\n",
        "\n",
        "Пакет PyTorchViz содержит средства визуализации графов вычислений. Установите его:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAckCUd1j2j6",
        "colab_type": "code",
        "outputId": "7a2fabe6-c886-49e0-d07c-b0a9a02b5472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8t6nPBcEI4u",
        "colab_type": "text"
      },
      "source": [
        "Подготовим минималистичный код: два тензора с поддержкой градиентов, формулу прогнозирования, погрешость и лосс.\n",
        "\n",
        "Функция **make_dot(yhat)**, получающая на вход тензор, связанный с формулой прогнозирования, сформирует такое изображение графа:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJlTuHZiewG",
        "colab_type": "code",
        "outputId": "584e9cd5-7098-42db-c36f-c3351817a183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "import torchviz\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "torchviz.make_dot(loss) # визуализируем граф вычислений"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f4963fc36a0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"342pt\"\n viewBox=\"0.00 0.00 171.50 342.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-338 167.5,-338 167.5,4 -4,4\"/>\n<!-- 139953186509152 -->\n<g id=\"node1\" class=\"node\">\n<title>139953186509152</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"121,-21 23,-21 23,0 121,0 121,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139953186508928 -->\n<g id=\"node2\" class=\"node\">\n<title>139953186508928</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118.5,-78 25.5,-78 25.5,-57 118.5,-57 118.5,-78\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139953186508928&#45;&gt;139953186509152 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139953186508928&#45;&gt;139953186509152</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-56.7787C72,-49.6134 72,-39.9517 72,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-31.1732 72,-21.1732 68.5001,-31.1732 75.5001,-31.1732\"/>\n</g>\n<!-- 139953186436376 -->\n<g id=\"node3\" class=\"node\">\n<title>139953186436376</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"117,-135 27,-135 27,-114 117,-114 117,-135\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139953186436376&#45;&gt;139953186508928 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139953186436376&#45;&gt;139953186508928</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-113.7787C72,-106.6134 72,-96.9517 72,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-88.1732 72,-78.1732 68.5001,-88.1732 75.5001,-88.1732\"/>\n</g>\n<!-- 139953792031936 -->\n<g id=\"node4\" class=\"node\">\n<title>139953792031936</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-192 26,-192 26,-171 118,-171 118,-192\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139953792031936&#45;&gt;139953186436376 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139953792031936&#45;&gt;139953186436376</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-170.7787C72,-163.6134 72,-153.9517 72,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-145.1732 72,-135.1732 68.5001,-145.1732 75.5001,-145.1732\"/>\n</g>\n<!-- 139951899956224 -->\n<g id=\"node5\" class=\"node\">\n<title>139951899956224</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-263 0,-263 0,-228 54,-228 54,-263\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139951899956224&#45;&gt;139953792031936 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139951899956224&#45;&gt;139953792031936</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-227.6724C45.4798,-219.2176 52.5878,-209.1085 58.6352,-200.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-202.4169 64.4601,-192.2234 55.8452,-198.3906 61.5714,-202.4169\"/>\n</g>\n<!-- 139951899956840 -->\n<g id=\"node6\" class=\"node\">\n<title>139951899956840</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-256 72.5,-256 72.5,-235 163.5,-235 163.5,-256\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-242.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139951899956840&#45;&gt;139953792031936 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139951899956840&#45;&gt;139953792031936</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-234.9317C103.7191,-225.6309 93.821,-211.8597 85.7479,-200.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-198.3753 79.761,-192.2979 82.7553,-202.4608 88.4395,-198.3753\"/>\n</g>\n<!-- 139951899957680 -->\n<g id=\"node7\" class=\"node\">\n<title>139951899957680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-334 91,-334 91,-299 145,-299 145,-334\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139951899957680&#45;&gt;139951899956840 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139951899957680&#45;&gt;139951899956840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-298.9494C118,-289.058 118,-276.6435 118,-266.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-266.0288 118,-256.0288 114.5001,-266.0289 121.5001,-266.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzxnH0iEEUAM",
        "colab_type": "text"
      },
      "source": [
        "Синие квадратики -- это наши параметры, тензоры, для которых считаются градиенты. Серые квадратики -- это операции Python над этими тензорами или над зависимыми от них значениями.\n",
        "\n",
        "Зелёные квадратики -- то же, что и серые, только в них вычисляются градиенты.\n",
        "\n",
        "Кто знаком с абстрактным синтаксическим деревом, наверняка увидит тут определённое сходство.\n",
        "\n",
        "По названиям квадратов легко определить их смысл -- префиксы определяют вид арифметических операций. Сперва Mul (умножение) выполняет умножение одного параметра: b * x_train_tensor, затем результат складывается (Add) с вторым параметром a, далее из y_train_tensor вычитается (Sub) что получилось, затем возводится в степень (Pow), и наконец вычисление среднего Mean -- это заключительная точка, в которой будут рассчитываться градиенты.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " \n",
        "**Вычисление градиентов в графе происходит снизу вверх!** Зелёный квадрат -- это стартовая точка такого процесса. Не вдаваясь в детали, отметим, что это так называемое **обратное автоматическое дифференцирование** -- мы начинаем с операции, где было получено результирующее значение, и движемся от неё обратно по графу, вычисляя таким образом производные.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU8kqbrEE0ek",
        "colab_type": "text"
      },
      "source": [
        "Почему в одних случаях в квадраты входят две стрелки (как и должно быть с точки зрения двух параметров арифметических операций), а в других всего одна? Какой там второй параметр арифметической операции?\n",
        "\n",
        "Дело в том, что в графе не требуются отдельные квадраты для, например, x или y, потому что мы не считаем градиенты для них. Независимо от количества задействованных тензоров в выражении **в графе учитываются только те параметры, для которых вычисляются градиенты**.\n",
        "\n",
        "Например, попробуйте изменить в команде создания параметра \"a\" его настройку requires_grad на False:\n",
        "\n",
        "`a = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)`\n",
        "\n",
        "Получится граф из шести квадратиков, которые будут линейно связаны друг с другом одиночными стрелками.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcUP191pFnNO",
        "colab_type": "text"
      },
      "source": [
        "##**Задание 1**\n",
        "\n",
        "Выведите графы для error и yhat -- почему получились такие отличия?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4o_iqiMF7NY",
        "colab_type": "text"
      },
      "source": [
        "##**Дифференцирование условных конструкций**\n",
        "\n",
        "Самая крутая особенность динамического вычислительного графа в PyTorch в том, что он понимает фактически любые управляющие конструкции Python, код любой сложности. Это по сути означает, что их тоже можно дифференцировать!\n",
        "\n",
        "Следующий код, дополненный условием (оно само по себе не имеет никакого смысла), выведет интересный граф:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Ne289G42UQ",
        "colab_type": "code",
        "outputId": "d6cacae6-5a22-475b-f52a-9effff92cbe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "import torchviz\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "# это полная чушь! этот код только для демонстрации разветвления в графе!\n",
        "if loss > 0:\n",
        "  yhat2 = b * x_train_tensor\n",
        "  error2 = y_train_tensor - yhat2\n",
        "  \n",
        "loss += error2.mean()  \n",
        "\n",
        "torchviz.make_dot(loss) # визуализируем граф вычислений"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f4916ff6a20>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"284pt\" height=\"399pt\"\n viewBox=\"0.00 0.00 284.00 399.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 395)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-395 280,-395 280,4 -4,4\"/>\n<!-- 139951895177648 -->\n<g id=\"node1\" class=\"node\">\n<title>139951895177648</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"215,-21 123,-21 123,0 215,0 215,-21\"/>\n<text text-anchor=\"middle\" x=\"169\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139951895177816 -->\n<g id=\"node2\" class=\"node\">\n<title>139951895177816</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"180,-78 82,-78 82,-57 180,-57 180,-78\"/>\n<text text-anchor=\"middle\" x=\"131\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139951895177816&#45;&gt;139951895177648 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139951895177816&#45;&gt;139951895177648</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M138.1475,-56.7787C143.2429,-49.1357 150.2317,-38.6524 156.2694,-29.596\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159.2497,-31.4352 161.8845,-21.1732 153.4253,-27.5522 159.2497,-31.4352\"/>\n</g>\n<!-- 139951895177984 -->\n<g id=\"node3\" class=\"node\">\n<title>139951895177984</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159.5,-135 66.5,-135 66.5,-114 159.5,-114 159.5,-135\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139951895177984&#45;&gt;139951895177816 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139951895177984&#45;&gt;139951895177816</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M116.3857,-113.7787C118.6987,-106.4542 121.8354,-96.5211 124.61,-87.7352\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.9557,-88.763 127.6295,-78.1732 121.2806,-86.655 127.9557,-88.763\"/>\n</g>\n<!-- 139951895178096 -->\n<g id=\"node4\" class=\"node\">\n<title>139951895178096</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"158,-192 68,-192 68,-171 158,-171 158,-192\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139951895178096&#45;&gt;139951895177984 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139951895178096&#45;&gt;139951895177984</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113,-170.7787C113,-163.6134 113,-153.9517 113,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.5001,-145.1732 113,-135.1732 109.5001,-145.1732 116.5001,-145.1732\"/>\n</g>\n<!-- 139951895178208 -->\n<g id=\"node5\" class=\"node\">\n<title>139951895178208</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159,-249 67,-249 67,-228 159,-228 159,-249\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139951895178208&#45;&gt;139951895178096 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139951895178208&#45;&gt;139951895178096</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113,-227.7787C113,-220.6134 113,-210.9517 113,-202.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.5001,-202.1732 113,-192.1732 109.5001,-202.1732 116.5001,-202.1732\"/>\n</g>\n<!-- 139951895178320 -->\n<g id=\"node6\" class=\"node\">\n<title>139951895178320</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-320 0,-320 0,-285 54,-285 54,-320\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139951895178320&#45;&gt;139951895178208 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139951895178320&#45;&gt;139951895178208</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.9558,-284.6724C63.3538,-275.446 78.3987,-264.2498 90.5683,-255.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.9097,-257.8138 98.8425,-249.0358 88.7306,-252.1981 92.9097,-257.8138\"/>\n</g>\n<!-- 139951895178376 -->\n<g id=\"node7\" class=\"node\">\n<title>139951895178376</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-313 72.5,-313 72.5,-292 163.5,-292 163.5,-313\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-299.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139951895178376&#45;&gt;139951895178208 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139951895178376&#45;&gt;139951895178208</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M117.1744,-291.9317C116.4837,-283.0913 115.4775,-270.2122 114.6261,-259.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.1119,-258.9949 113.8436,-249.2979 111.1332,-259.5402 118.1119,-258.9949\"/>\n</g>\n<!-- 139951895178544 -->\n<g id=\"node8\" class=\"node\">\n<title>139951895178544</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"199,-391 145,-391 145,-356 199,-356 199,-391\"/>\n<text text-anchor=\"middle\" x=\"172\" y=\"-363.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139951895178544&#45;&gt;139951895178376 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139951895178544&#45;&gt;139951895178376</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M158.6517,-355.9494C150.6484,-345.4266 140.4734,-332.0484 132.3053,-321.3089\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.8474,-318.8695 126.0078,-313.0288 129.2757,-323.1071 134.8474,-318.8695\"/>\n</g>\n<!-- 139951895178264 -->\n<g id=\"node11\" class=\"node\">\n<title>139951895178264</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272.5,-313 181.5,-313 181.5,-292 272.5,-292 272.5,-313\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-299.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139951895178544&#45;&gt;139951895178264 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139951895178544&#45;&gt;139951895178264</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M185.5955,-355.9494C193.8285,-345.3214 204.3179,-331.7806 212.6787,-320.9875\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.4868,-323.0778 218.8439,-313.0288 209.9529,-318.7909 215.4868,-323.0778\"/>\n</g>\n<!-- 139951895177872 -->\n<g id=\"node9\" class=\"node\">\n<title>139951895177872</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"276,-135 178,-135 178,-114 276,-114 276,-135\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139951895177872&#45;&gt;139951895177648 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139951895177872&#45;&gt;139951895177648</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.6475,-113.9795C211.9855,-94.9888 191.4875,-54.6995 179.1119,-30.3751\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.1629,-28.6533 174.5088,-21.3276 175.9239,-31.8275 182.1629,-28.6533\"/>\n</g>\n<!-- 139951895178040 -->\n<g id=\"node10\" class=\"node\">\n<title>139951895178040</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272,-249 182,-249 182,-228 272,-228 272,-249\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139951895178040&#45;&gt;139951895177872 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139951895178040&#45;&gt;139951895177872</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-227.9795C227,-209.242 227,-169.7701 227,-145.3565\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-145.3276 227,-135.3276 223.5001,-145.3277 230.5001,-145.3276\"/>\n</g>\n<!-- 139951895178264&#45;&gt;139951895178040 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139951895178264&#45;&gt;139951895178040</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-291.9317C227,-283.0913 227,-270.2122 227,-259.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-259.2979 227,-249.2979 223.5001,-259.2979 230.5001,-259.2979\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV4DeKF9GB3A",
        "colab_type": "text"
      },
      "source": [
        "**Важно**. В графе формируется не линейная последовательность действий, как в коде. \n",
        "\n",
        "**Граф -- это не блок-схема!** В случае блок-схемы алгоритма требовалось бы делать разветвление после первого расчёта loss, а в данном случае видны два независимых вычислительных блока, которые разветвляются не по условию if loss > 0 , а по вхождению параметров (в данном случае параметра b) в различные цепочки вычислений. Эти блоки/цепочки в процессе вычисления градиентов комбинируются автоматически.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fR3Zp9aHz5m",
        "colab_type": "text"
      },
      "source": [
        "##**Оптимизатор**\n",
        "\n",
        "Несмотря на автоматическое вычисление градиентов, сейчас мы, как и в случае с NumPy, параметры обновляем вручную, явными командами в коде. Сейчас их всего два, но что если их будут сотни или тысячи, как в крупных и сложных моделях? На помощь приходят оптимизаторы. **Пакет torch.optim -- это второй из трёх ключевых пакетов PyTorch**.\n",
        "\n",
        "\n",
        "\n",
        "Оптимизатор получает на вход список параметров, скорость обучения и возможно ещё ряд других настроечных коэффициентов, и выполняет их автоматическое обновление с помощью метода **step().** Не требуется в таком случае и ручного обнуления градиентов -- для этого есть метод **zero_grad()**.\n",
        "\n",
        "\n",
        "Различные алгоритмы оптимизации и реализованы в данном пакете torch.optim.  Один из популярных алгоритмов -- это **стохастический градиентный спуск** (Stochastic Gradient Descent, SGD). Как он работает внутри, на данном шаге неважно, достаточно знать, что он умеет реализовывать пакетный спуск -- используя в обновлении сразу всю обучающую выборку.\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html?source=post_page---------------------------#torch.optim.SGD\n",
        "\n",
        "Всё, что потребуется изменить в исходном коде -- это создать сам оптимизатор, связав его с параметрами, и соответственно, сменить ручное обновление параметров a и b и обнуление их градиентов на вызов методов оптимизатора step() и zero_grad().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mohMh0ECmw1K",
        "colab_type": "code",
        "outputId": "12af900c-7b9c-48f6-fac4-62c9bdea98d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "# скорость обучения\n",
        "lr = 0.1\n",
        "\n",
        "# количество эпох\n",
        "n_epochs = 1000 \n",
        "\n",
        "# создаём SGD оптимизатор для автоматического обновления параметров \n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    loss.backward()\n",
        "    \n",
        "    # with torch.no_grad():\n",
        "    #    a -= lr * a.grad\n",
        "    #    b -= lr * b.grad\n",
        "    optimizer.step()  \n",
        "    \n",
        "    # a.grad.zero_()\n",
        "    # b.grad.zero_()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7RIFwl0ISpm",
        "colab_type": "text"
      },
      "source": [
        "Параметры в начале и после обучения:\n",
        "\n",
        "\n",
        "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
        "\n",
        "\n",
        "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n",
        "\n",
        "По сути, мы таким образом оптимизировали процесс оптимизации!\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhSl1VXCIiQc",
        "colab_type": "text"
      },
      "source": [
        "##**Лосс**\n",
        "\n",
        "Сейчас и лосс мы пока считаем вручную, явно записывая формулу расчёта \n",
        "loss = (error ** 2).mean(). На помощь приходит **третий (из трёх) ключевой пакет PyTorch -- torch.nn**, добавляющий уровень абстракции для довольно низкоуровневых возможностей autograd.\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html?highlight=nn#module-torch.nn\n",
        "\n",
        "В нём, в частности, содержится набор стандартных функций для расчёта всевозможных видов ошибок/погрешностей.\n",
        "\n",
        "В нашем случае, функция расчёта среднеквадратичной ошибки называется **MSELoss**. Сама по себе это не функция, которая вызывается напрямую, а скорее \"фабрика\" функций, которая создаёт нужную нам функцию, причём можно этой фабрике задавать параметры желаемой функций, методы агрегации данных (например, reduction=\"mean\" означает вычисление среднего, reduction=\"sum\" означает вычисление суммы). На вход подобным функциям подаётся обучающая выборка и тензор с параметрами, для которых рассчитываются градиенты.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93krP0x3uCY8",
        "colab_type": "code",
        "outputId": "6701f74a-30f2-415a-f838-b94496ed43d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch import optim, nn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "# скорость обучения\n",
        "lr = 0.1\n",
        "\n",
        "# количество эпох\n",
        "n_epochs = 1000 \n",
        "\n",
        "# функция расчёта лосса\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# создаём SGD оптимизатор для автоматического обновления параметров \n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # error = y_train_tensor - yhat\n",
        "    # loss = (error ** 2).mean()\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()  \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1znvwTI7lw",
        "colab_type": "text"
      },
      "source": [
        "Обратите внимание, что мы уже избавились фактически от всего ручного кодирования, связанного с градиентами и другими оптимизационными расчётами!\n",
        "\n",
        "**Получился по сути шаблон, в котором осталась только явно одна задаваемая вручную строка, где вычисляется yhat -- она определяет нашу формулу прогноза, и её можно менять на любые другие нужные нам для анализа зависимости.**\n",
        "\n",
        "Соответственно, напрашивается вопрос, а можно ли как-то абстрагировать и этот момент, чтобы не искать в оптимизационном коде нужную строчку, да и в целом перейти на более удобный формат представления изучаемых зависимостей? Такая форма абстракции в PyTorch -- это модель.\n",
        "\n",
        "Созданию моделей PyTorch посвящено следующее занятие."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W1syOJ0Oo9a",
        "colab_type": "text"
      },
      "source": [
        "##**Задание 2**\n",
        "\n",
        "Измените в данном шаблоне прогноз на основе линейной регрессии на более сложную зависимость. С функциями прогноза какой сложности сможет уверенно справиться наш простой базовый шаблон PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d3WkxEVV1F-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://vk.com/lambda_brain"
      ]
    }
  ]
}