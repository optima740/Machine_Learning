{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1_6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ov4K97EJbu4",
        "colab_type": "text"
      },
      "source": [
        "# **Занятие 6. Свёрточные нейронные сети. Классификация цветных изображений**\n",
        "\n",
        "https://vk.com/lambda_brain\n",
        "\n",
        "Рассмотрим случай, когда входные данные -- это цветные изображения. Для обработки таких данных были придуманы **свёрточные нейронные сети**, воспользуемся для этого одной из классических моделей.\n",
        "\n",
        "---\n",
        "\n",
        "Импортируем нужные пакеты:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abpHoRq6V-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goNhmuPOJ-BV",
        "colab_type": "text"
      },
      "source": [
        "Будем обрабатывать стандартный датасет **CIFAR10**, который включает фотографии десяти классов: самолёт, автомобиль, птица, кот, олень, собака, лягушка, лошадь, корабль и грузовик. На каждый класс приходится по 6000 (5000 обучающих и 1000 тестовых) цветных изображений размером 32 * 32 пиксела (и три канала цветности RGB)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfwVbruB8gQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 3*32*32   # Размер изображения в точках * количество цветов\n",
        "num_classes = 10       # Количество распознающихся классов (10 видов изображений)\n",
        "n_epochs = 2           # Количество эпох\n",
        "batch_size = 4         # Размер мини-пакета входных данных\n",
        "lr = 0.001             # Скорость обучения"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPSaBAmrKJ5p",
        "colab_type": "text"
      },
      "source": [
        "Из-за специфики представления цветных изображений мы не можем сразу брать их в сыром виде: сперва требуется нормализовать картинки, превратить их в изображения с интенсивностью цвета в диапазоне 0..1. Это делает стандартная функция **Normalize()** из torchvision.transforms, которой в качестве параметров в подобных случаях обычно указываются стандартные значения (среднее и стандартное отклонение) для такой нормализации (0.5, 0.5, 0.5).\n",
        "\n",
        "То есть нам нужно выполнить композицию трансформаций: сперва выполнить преобразование в тензоры, и затем нормализовать. \n",
        "\n",
        "Композицию выполняет стандартная функция torchvision.transforms **.Compose()**. Её результат мы и задаём в качестве параметра transform конструктора CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eX2jdtCLzWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "cifar_trainset = dsets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbncbyBiKid7",
        "colab_type": "text"
      },
      "source": [
        "Аналогично подготовим и тестовый датасет:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jKhtNW7L7YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_testset = dsets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "print(len(cifar_trainset))\n",
        "print(len(cifar_testset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lug1CvTJKmHb",
        "colab_type": "text"
      },
      "source": [
        "Загрузим наши данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brvDSwBVNqqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=cifar_trainset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=cifar_testset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeC-wQZ0KpJq",
        "colab_type": "text"
      },
      "source": [
        "Добавим стандартный шаг обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBltxfGOChj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# импортируем нужные библиотеки\n",
        "import torch\n",
        "import numpy as np # всегда пригодится :)\n",
        "from torch.nn import Linear, Sigmoid\n",
        "\n",
        "# инициализируем девайс\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# добавляем типовую функцию \"шаг обучения\"\n",
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    def train_step(x, y):\n",
        "        model.train()\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        return loss.item()\n",
        "    return train_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdK0PPStSWwH",
        "colab_type": "text"
      },
      "source": [
        "Какую задействовать модель? Вообще, конструирование наиболее эффективных моделей -- это искусство плюс математика. На практике часто можно пользоваться либо простыми стандартными решениями (как было например в случае распознавания рукописных цифр), либо сложными моделями, которые под соответствующие классы задач придумали ведущие специалисты в ML. \n",
        "В нашем случае мы применим модель LeNet, предложенную Яном ЛеКуном -- она относится к так называемым **свёрточным нейронным сетям (Convolutional Neural Network, CNN)**, хорошо работающим с двумерными изображениями.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Подробное описание принципов работы CNN:\n",
        "\n",
        "https://neurohive.io/ru/tutorial/cnn-na-pytorch/\n",
        "\n",
        "Главное, обратите внимание на принцип **свёртки** и движущееся окно/**фильтр**.\n",
        " \n",
        "**Пулинг (pooling)** -- это схожая со скользящим окном техника, когда вместо свёртки по обучаемым весам к значениям в окне применяется некоторая статистическая функция (среднее, максимум, ...). Так, популярная механика тут -- это max pooling. Пулинг выполняет обобщение мелких деталей, устойчиво выделяет некоторый признак независимо от его размера и ориентации.\n",
        "\n",
        "**Канал** -- это множество фильтров, формирующих оригинальный двумерный вывод. Каналы нередко связываются с цветностью изображения.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVIF0OHjvkRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CifarModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CifarModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoZi7iOLTDUH",
        "colab_type": "text"
      },
      "source": [
        "Рассмотрим структуру этой модели подробнее.\n",
        "\n",
        "По мелким техническим причинам (необходимость выравнивания данных при переходе от свёрточных слоёв к линейным) её удобнее представить в формате классической модели, а не просто композицией слоёв.\n",
        "\n",
        "Первый слой -- Conv2d(3, 6, 5) с функцией активации ReLU создаёт набор свёрточных фильтров. Первый параметр 3 -- это количество входных каналов изображений, три цвета. Второй параметр 6 -- это количество выходных каналов, третий параметр -- размер фильтра 5x5. На выходе получается 6 фильтров размером 3x5x5 -- и всего модель выделяет (3 * 5 * 5 + 1) * 6 = 456 параметров.\n",
        "Выходной размер слоя получится 6 * 28 * 28 , где 28 = ((32 - 5) + 1)\n",
        "\n",
        "Метод MaxPool2d(2,2) -- это реализация max-пулинга (вычисление его аргументов см. по ссылке выше). kernel_size -- размер окна пулинга, stride -- шаг пулинга. Выходной размер слоя таким образом снижаем в два раза: с 6 * 28 * 28 до 6 * 14 * 14.\n",
        "\n",
        "\n",
        "Далее снова применяется функция Conv2d(6, 16, 5) -- шесть выходных каналов предыдущей функций как входы. Теперь мы применяем 16 фильтров (каждый размером 6 * 5 * 5), и выходной размер слоя будет 16 * 10 * 10, где 10 = (14 - 5) + 1. Всего на уровне обрабатывается (5 * 5 * 6 + 1) * 16 = 2416 параметров.\n",
        "\n",
        "Следующий max pooling снижает этот выход в два раза -- с 16 * 10 * 10 до 16 * 5 * 5.\n",
        "\n",
        "И в заключение добавляются три полносвязных слоя Linear. Обратите внимание, что перед ними надо выполнить модификацию структуры передаваемых данных, так как свёрточные слои работают с двумерными изображениями, а линейные -- с векторными наборами. Такое преобразование выполняет x.view(-1, 16 * 5 * 5).\n",
        "\n",
        "Первый линейный слой из 120 узлов, получает 16 * 5 * 5 входов -- то есть в нём требуется (16 * 5 * 5 + 1) * 120 = 48120 параметров, и далее количество входов-выходов понижается через следующие слои до наших итоговых 10 классов (последний уровень требует (84+1) * 10 = 850 параметров).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlW-CkjeOn2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim, nn\n",
        "\n",
        "model = CifarModel()\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  \n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        loss = train_step(images, labels)\n",
        "        \n",
        "# print(model.state_dict())    \n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-zC19n5X_-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad(): # проверяем на тестовой выборке\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Точность: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Kd4ku8b-9b",
        "colab_type": "text"
      },
      "source": [
        "Считаем точность -- она получается в районе 55%. Это хороший результат, так как при случайном выборе мы получили бы 10%. Причём её можно существенно повысить -- уже после 10 эпох обучения мы получим точность 80+%!\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX96AyHbcxSr",
        "colab_type": "text"
      },
      "source": [
        "В заключение вычислим точность распознавания по каждому из признаков:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LzRkaZXxb9k",
        "colab_type": "code",
        "outputId": "0b995010-6659-4dea-f464-d54220c86322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Точность для %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Точность для самолёт : 68 %\n",
            "Точность для автомобиль : 64 %\n",
            "Точность для птица : 24 %\n",
            "Точность для   кот : 48 %\n",
            "Точность для олень : 45 %\n",
            "Точность для собака : 51 %\n",
            "Точность для лягушка : 56 %\n",
            "Точность для лошадь : 60 %\n",
            "Точность для корабль : 74 %\n",
            "Точность для грузовик : 49 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNjHoPddEUb",
        "colab_type": "text"
      },
      "source": [
        "## **Задание.** \n",
        "Увеличение количества эпох (шагов обучения) существенно повышает качество модели. Но есть и другие способы -- поэкспериментируйте например с добавлением новых свёрточных или линейных слоёв, размерами фильтров и их количеством. В процессе экспериментов избегайте переобучения -- когда модель показывает отличные результаты на обучающей выборке, но невысокие на тестовой.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "В следующем занятии мы займёмся экспериментами с уже обученными моделями."
      ]
    }
  ]
}